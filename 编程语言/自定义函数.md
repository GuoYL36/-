# 自定义函数

## pytorch构建自己的数据集
```python
import torch
import torch.nn as nn
from torch.autograd import Variable
import torch.utils.data as Data
import torchvision

torch.manual_seed(1)

# 构建自己的数据集，例子如下
# train_data, test_data：numpy.array类型，[[],[],...]
# train_label：numpy.array类型，[]

torch_dataset = Data.TensorDataset(torch.from_numpy(train_data).double(),torch.from_numpy(train_label).double())
loader = Data.DataLoader(dataset=torch_dataset, batch_size=20,shuffle=True,num_workers=2)

test_data = Variable(torch.from_numpy(test_data).unsqueeze(1)).type(torch.FloatTensor)


# 构建模型
class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        # 定义要使用神经网络函数，例子如下
        self.conv1 = nn.Conv1d(1,128,3)
        self.relu1 = nn.ReLU()
        self.conv2 = nn.Conv1d(128,64,3)
        self.relu2 = nn.ReLU()
        self.maxpool = nn.MaxPool1d(2)
        self.out = nn.Linear(1792,2)
        
    def forward(self, x):
        # 搭建神经网络，例子如下
        x = self.conv1(x)
        x = self.relu1(x)
        x = self.conv2(x)
        x = self.relu2(x)
        x = self.maxpool(x)
        x = x.view(x.size(0),-1)

        output = self.out(x)
        
        return output
    
model = Model()

# 构建损失函数和优化方法
optimizer = torch.optim.Adam(model.parameters(), lr=LR)
loss_func = nn.CrossEntropyLoss()

for epoch in range(EPOCH):
    for step, (x,y) in enumerate(loader):
        b_x = Variable(x).float()  # 训练集数据输入类型
        b_y = Variable(y).type(torch.LongTensor)   # 训练集标签类型
        b_x = b_x.unsqueeze(1)
#         print(b_x.size())
        output = model(b_x)
        loss = loss_func(output,b_y)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        if step %50 ==0:
            test_output = model(test_data)
            
            pred_y = torch.max(test_output, 1)[1].data.numpy() # torch.max返回两个值，一个是最大值本身，一个是最大值的索引
            accuracy = float((pred_y==test_label).astype(int).sum())/float(test_label.size)
            print("epooch:  %d, | train loss: %f, | test accuracy: %f"%(epoch, loss, accuracy))

```

## 计算余弦相似度
> 两种方法
+ 第一种
    ```python
    def cosineSimilarity(vector_a,vector_b):
            """
        计算两个向量之间的余弦相似度
        :param vector_a: 向量 a
        :param vector_b: 向量 b
        :return: sim
        """
        vector_a = np.mat(vector_a)
        vector_b = np.mat(vector_b)
        num = float(vector_a * vector_b.T)
        denom = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)
        cos = num / denom
        
        return cos
    ```

+ 第二种
    ```python
    def cosineSimilarity(list_a,list_b):
            """
        计算两个数组之间的余弦相似度
        :param list_a: 数组 a
        :param list_b: 数组 b
        :return: cos
        """
        vector_a = np.mat(list_a)
        vector_b = np.mat(list_b)
        num = float(vector_a * vector_b.T)
        denom = np.sqrt(np.sum(np.power(vector_a,2)))*np.sqrt(np.sum(np.power(vector_b,2)))
        cos = num / denom
        
        return cos
    ```
    


































