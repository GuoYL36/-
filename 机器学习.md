
## 入门机器学习后的“随笔”

### 偏差和方差
+ 偏差：算法期望预测和真实预测之间的偏差程度。反应的是模型本身的拟合能力。
+ 方差：度量了同等大小的训练集的变动导致学习性能的变化，刻画了数据扰动导致的影响。
-----

### 欠拟合underfitting
+ **解决措施**
	+ 添加其它特征项（增大数据量）
	+ 添加多项式特征（增加网络层数）
	+ 减少正则化参数
	
### 过拟合overfitting
+ **解决措施**
	+ 重新清洗数据
	+ 增大数据的训练量
	+ 采用正则化方法
	+ 采用dropout法
	+ 提前终止训练
	+ 减少网络层数

### 梯度消失和梯度爆炸
+ **原理**
	+ 梯度消失：当网络层数很深时，如果梯度小于1，则会使得经过多层后向反馈后的梯度累乘远远小于1；
	+ 梯度爆炸：与梯度消失相反，当网络层数很深时，如果梯度大于1，则会使得经过多层后向反馈后的梯度累乘远远大于1；

+ **解决措施**
	+ 1. 激活函数的选择（使用ReLU代替sigmoid、tanh等）
	+ 2. 预训练 + 微调
	+ 3. 使用Batch Normalization
	+ 4. 使用残差网络结构
	+ 5. 使用LSTM网络
		+ 为什么LSTM比RNN更能解决梯度消失的问题？
			+ 因为在RNN中，BPTT的梯度是累乘形式，而RNN的输出中采用了tanh激活函数，所以会出现梯度消失问题；而LSTM的梯度除了累乘形式，还有累加形式，所以不容易出现梯度消失。
		+ LSTM中用sigmoid激活函数，而不用ReLU激活函数的原因？
			+ 因为在LSTM中，忘记门和更新门是起筛选作用，所以需要0~1之间的值作为概率来进行筛选。
	+ 6. 梯度剪切、权重正则

----
	
### 归一化
+ **机器学习为什么对数据进行归一化？**
	+ 归一化的目的：
		+ 处理不同规模和量纲的数据，使其缩放到相同的数据区间和范围，以减少规模、特征、分布差异对模型的影响。
		+ 归一化加速GD求解最优解的速度。比如收敛路径呈Z字型，导致收敛太慢；
		+ 归一化可能提高精度。
	
+ **机器学习什么情况下对数据进行归一化？**
	+ 使用了梯度下降算法，如LR、SVM等；
	+ 计算样本点距离时，如KNN、K-Means等。
	+ ......
+ **机器学习什么情况下不需要归一化？**
	+ 概率模型（决策树）不需要归一化。

+ **常用的归一化方法**
	+ max-min法：容易受极端值的影响，一定程度上会破坏原有的数据结构；
	+ z-score法：会改变原有数据的分布，不适合对稀疏数据做处理，不适合根据变量差异程度的聚类分析；
	+ RobustScaler：适用于存在离群点的数据。
	+ 上述方法分析：在分类中，聚类算法，数据符合正态分布中，需要使用距离来度量相似性或者使用PCA降维时，z-score表现得较好。在不涉及距离测量，协方差计算，数据不太符合正态分布时，可以使用第一种方法或其他方法。

+ **LR归一化问题，什么情况下可以不归一化，什么情况下必须归一化，为什么？**
	+ ......
-----

### Logistical Regression
+ **LR作为线性模型，如何拟合非线性情况？**
	+ **特征侧**：离散化、交叉组合
	+ **模型**：引入kernel，或推广到FM等model。

+ **提到LR损失函数要能知道交叉熵，为什么使用交叉熵？使用交叉熵为损失函数的优化问题是在优化什么量？交叉熵和KL散度、相对熵的关系？**
	+ ......
	+ ......

+ **LR的分布式实现逻辑是怎样的？数据并行和模型并行的区别？P-S架构是什么东西？**
	+ ......
	+ ......

-----
### 海量离散特征用简单模型、少量连续特征用复杂模型。
-----

### SVM
+ **优缺点**
	+ 解决小样本情况下的机器学习问题；
	+ 提高泛化能力；
	+ 处理高维空间数据；
	+ 解决非线性问题；
	+ 对于线性问题没有通用的解决方案，谨慎选择kernel函数；
	+ 处理分类问题时，要求解函数的二次规划问题，需要大量的存储空间。

+ **SVM中假设分离超平面系数非常大怎么办？**
	+ ......

+ **针对数据和特征的关系，如何选择SVM核函数？**
	+ 1. 特征数量和样本数量差不多时，选用LR或线性核的SVM；
	+ 2. 特征数量少、样本数量正常时，选用SVM+高斯核函数；
	+ 3. 特征数量少、样本数量很大时，需要手工添加一些特征变成第一种情况；
	+ 4. 特征数量少、样本数量少时，选用SVM + 非线性核。

+ **SVM常用核函数**
	+ linear核：主要用于线性可分情况，参数少，速度快；
	+ RBF核：主要用于线性不可分情况；（**注意：linear核是RBF核的一种特例**）
	+ sigmoid核

+ **常用核函数选择**
	+ 可以先用linear核函数看看效果，不好再用RBF核函数；
	+ 一般RBF核函数的性能位于linear核和sigmoid核之间，这也是为什么一般选用RBF核的原因。
	+ 如果对样本没有先验信息，则可以利用cross validation方法来评估不同核函数的性能，再选出性能最好的核函数。

-----

### LR和SVM的异同
+ **同：**
	+ 都是监督学习算法，都是判别模型；
	+ 都可以处理分类问题，一般都处理线性分类问题（**注意：LR也可以使用核函数**）；
	+ 两者都可以使用不同的正则化项，并在很多实验中，两者性能相当。
	
+ **异：**
	+ 损失函数不同，一个是Logistical loss，一个是Hinge loss；
	+ LR是参数模型，对异常值敏感；SVM是非参数模型；
	+ LR训练时考虑所有数据，容易受数据不平衡的影响；而SVM只依赖于支持向量，但是由于SVM基于间隔分类，一般要对数据做归一化处理。
	+ 对于非线性问题，SVM通常采用核函数解决，而LR很少用。这是因为使用核函数，SVM只要支持向量参与计算，而LR则是所有数据都参与计算，复杂度高。

----

### 集成方法
+ 关注降低variance，选择bias较小的基学习器
	+ **Bagging**
		+ 给定m个样本的数据集，利用有放回的随机采样法，得到T个含有m个样本的训练集，然后训练基学习器得到T个基学习器，对分类任务采用**投票法**，对回归任务采用**平均法**。
		+ **每个基学习器只使用了m个样本中约63.2%的样本，剩下36.8%的样本可用作验证集。**
		+ **样本扰动**

	+ **Stacking**
		+ 从初始数据集中训练出T个初级学习器，然后将T个初级学习器的输出当做次级学习器的样例输入，而初始样本的标签仍作为样例标记，用新得到的数据集训练次级学习器。
	
	+ **Random Forest**
		+ **样本扰动+属性扰动**
	
+ 关注降低bias，选择variance较小的基学习器
	+ **AdaBoost**
		+ 从初始数据集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器出错的训练样本在后面训练过程中得到更多的关注，然后利用调整后的样本分布来训练下一个基学习器，如此重复，最后对每轮训练得到的基学习器进行加权后相加。**（基学习器常采用回归树和逻辑回归）**

----

### Random Forest
> 在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树节点分裂时引入**随机属性**扰动。

> **随机性**体现（与传统决策树的差异）：对基决策树的每个节点，先从该节点的属性集合中随机选择包含K(log2(d))个属性的子集，然后再从这个子集中选择一个最优的属性用于划分。

+ **为什么随机选取数据集？**
	+ 如果不随机的话，训练出来的多棵树的分类结果是一样的，违背了bagging思想;

+ **为什么有放回抽样？**
	+ RF在分类时是求同，有放回的抽样会产生相同的训练样本；如果不是有放回抽样，训练出来的每棵树的结果存在很大偏差，这样对分类结果没有任何帮助。所以有放回抽样能够减小bias，RF的目的是减小variance。

+ **影响RF分类结果的因素：**
	+ 任意两棵树的相关性：相关性越大，错误率越高；
	+ 每棵树的分类能力：分类器能力越强，错误率越低；
	+ 唯一可调参数：RF中特征子集的数量，数量越大，性能越好。

+ **RF的优缺点**
	+ RF引入两个随机性，抗噪能力增强；
	+ RF在分类中对各个变量的重要性进行估计，对泛化误差进行无偏估计；
	+ 可处理高维数据，对数据集的适应能力强；
	+ 性能由于单预测器，分类精度与boosting算法差不多，运行速度更快；
	+ 训练数据较少或噪声数据较大时，会发生overfitting。
-----

### GBDT
+ **GBDT优缺点：**
	+ 灵活处理各种离散值和缺失值；
	+ 对异常值具有鲁棒性；
	+ 相对SVM，预测的准确率较高；
	+ 由于弱学习器之间存在依赖关系，难以并行训练；
	+ 不适合处理高维稀疏数据，缺乏平滑处理。

+ **算法流程：**
	+ 多轮迭代，每轮迭代产生一个弱分类器，每个分类器在上一轮分类器的**残差**基础上进行训练。对弱分类器的要求一般是低variance和高bias的简单分类器，如CART树。最终分类器是将每轮训练得到的弱分类器加权求和得到的。**（采用不放回采样）**

+ **损失函数：**
	+ 一般损失函数的负梯度(一阶导)作为残差；（因为一般损失函数存在优化困难问题，所以取一阶导）

+ **选择特征：**
	+ 以CART树为例，原始GBDT遍历每个特征，然后对每个特征遍历它所有可能的切分点，找到最优特征J和最优切分点，即 min(J){min(c1)sum(y-c1)^2+min(c2)sum(y-c2)^2}。

+ **分裂节点的评价指标：**
	+ 分裂时选择使得误差下降最多的分裂。

+ **构建特征：**
	+ 利用GBDT产生特征的组合(CTR预估中，工业届一般用LR处理非线性数据，其中就可以用这种特征组合的方式增强LR对非线性分布的拟合能力)。比如，利用GBDT生成两棵树，根据叶子结点的个数生成一个向量，然后将样本分别输入进去，样本分到叶子结点处该向量位置值为1，其余为0，根据得到的这个向量作为该样本的组合特征。

+ **用于分类：**
	+ GBDT无论用于分类还是回归都是用CART树。对于K分类问题，每次迭代构建K棵树，然后利用softmax求出属于每棵树的概率，残差是真实label与第k棵树的概率的差值。

+ **GBDT减少误差的方式：**
	+ 每棵树拟合当前模型预测值和真实值之间的误差。

+ **正则化：**
	+ **学习率**：越小越易overfitting；
	+ **子采样比**：越小越易underfitting
	+ **剪枝操作**

+ **参数**
	+ **步长、学习率**：减小步长，提高泛化能力；学习率过大容易overfitting；
	+ **树最大深度**：太大overfitting
	+ **内部节点再划分所需最小样本数和叶子节点最少样本数**：内部节点再划分所需最小样本数越大越防overfitting
	+ **子采样比**：太小容易underfitting

+ **相比于SVM、LR，GBDT的优势：**
	+ 基于树模型，继承了树模型的优点
		+ 对异常点鲁棒；
		+ 不相关特征干扰性低；
		+ 能处理缺失值；
		+ 受噪声干扰小。

+ **高维稀疏特征的时候，LR的效果为什么会比GBDT好？**
	+ 因为LR等线性模型的正则项是对权重进行惩罚，而树模型的惩罚项通常为叶子结点数量和深度。因此带正则化的线性模型不容易overfitting。

+ **为什么GBDT、XGBoost每棵树的深度很浅，而Decision Tree、RF每棵树的深度很深？**
	+ GBDT关注降低bias，每棵树浅带来的variance低；
	+ RF关注降低variance，每棵树深带来的bias低。

+ **GBDT和Adaboost的区别**
	+ **异：**
		+ GBDT是利用残差来训练每棵decision tree；Adaboost通过误差来调整每个样本的权重，从而训练每棵decision tree。
		+ 损失函数不同：GBDT使用一般损失函数；Adaboost使用指数损失函数。

	+ **同：**
		+ 都可以用来分类，相对于经典判别分类方法，效果好；
		+ 由多棵树组成。
		
### XGBoost
+ **为什么XGBoost要以二阶导数值作为权重进行分位？**
	+ 从目标函数可以看出，二阶导数值对 loss 有加权作用。
	
+ **XGBoost如何处理稀疏值？**
	+ 当特征出现稀疏值时，XGBoost可学习出默认的节点分裂方向。将缺失值向左、右节点各分一次，计算最大的Gain，向Gain最大的方向分。
	
+ **XGBoost的其它特性**
	+ 行抽样、列抽样（借鉴Random Foreast）
	+ Shrinkage，即学习率，减小学习率，迭代次数增加，有正则化作用。（减小学习率，相当于每个叶节点分数变小）
	+ 支持自定义损失函数（需二阶可导）。
----
	
+ **GBDT和XGBoost的区别**
	+ XGBoost支持线性分类器，传统GBDT以CART作为基分类器；XGBoost支持线性分类器，相当于带L1和L2正则化的LR或线性回归。
	+ GBDT对损失函数求一阶导，而XGBoost对损失函数进行二阶泰勒展开；XGBoost支持自定义代价函数，代价函数需一阶和二阶可导；
	+ XGBoost在代价函数里加入正则项，用于控制模型的复杂度；
	+ XGBoost支持列抽样，借鉴了RF的做法，能降低overfitting，减少计算；
	+ XGBoost工具支持并行，并行是在特征上做的，GBDT每次节点分裂时，需要对所有特征计算并排序，而XGBoost预先对数据排序并保存为block结构（预排序算法），迭代过程中重复使用这个结构，大大减少计算量。在节点分裂时，特征增益的计算可以开多线程实现。在内存有限或分布式的情况下，数据无法一次性载入时，XGBoost用可并行的近似直方图算法能高效生成候选的分割点。
-----

### Gradient Descent
+ **BGD、SGD、MBGD的区别？**
	+ BGD：批量梯度下降法，每次迭代需要所有的样本，该方法可以得到全局最优解，但是会影响速度。
	+ SGD：随机梯度下降法，每次迭代使用一个样本，迭代次数多。该方法带来的噪声较多，非全局最优解，使得每次迭代并不是朝整体最优化方向，可能使准确率下降。但是训练速度快。
	+ MBGD：小批量梯度下降法，每次迭代需要部分样本。该方法是对上述两种方法的改进。
+ **不同的GD方法有什么区别和联系？**
	+ ...

+ **二阶优化算法有什么？**
	+ ...

+ **对比off-line和on-line learning的区别？**
	+ ...
----

### L1、L2正则
+ **关于L1和L2正则，其几何解释和概率解释**
	+ 从Bayes角度来看，L1、L2正则相当于对模型参数引入先验分布：
		+ L1正则：模型参数服从拉普拉斯分布，对参数加入分布约束，大部分取值为0。
			+ 特征选择：稀疏性（权值稀疏）
			+ 鲁棒性：忽略异常点
		+ L2正则：模型参数服从高斯分布，对参数加了分布约束，大部分取值很小。
			+ 解决过拟合
			+ 易优化和计算（权值平滑）
			+ 稳定性好
			+ 对异常点敏感：误差取平方后放大。
	+ 稳定性比较解释
		+ L1存在**ill condition（病态）问题**：输入发生微小变化导致输出发生很大改变。
	+ 稀疏解和平滑解解释
		+ 从目标函数看，等高线与约束条件首次相交的地方为最优解。
			+ ![L1产生稀疏性](https://i.loli.net/2019/04/12/5cb05448ba10e.jpg)
			+ ![L2产生平滑解](https://i.loli.net/2019/04/12/5cb05495ae346.jpg)
			
		+ 从优化角度看：
			+ ![L1和L2的更新量](https://i.loli.net/2019/04/12/5cb0554600a16.jpg)
			+ L1的权值更新量：w_(i+1) = w_i - \eta
			+ L2的权值更新量：w_(i+1) = w_i - \eta * w_i
			
	

----

### Metrics

| 预测<br><br>实际| 1  | 0 |    |
| :--------: | :--------: | :--------: |:--------:|
| 1  |   TP   |   FN  |   TP+FN  |
| 0  |   FP   |   TN  |   FP+TN  |
|    | TP+FP  | FN+TN | TP+FN+FP+TN |

+ **准确率**：（TP+TN）/（TP+TN+FP+FN）
+ **错误率**：（FP+FN）/（TP+TN+FP+FN）
+ **召回率(Recall)、查全率**：实际的正样本中，分类成正样本的比例，（TP）/（TP+FN）
+ **精确率(Precision)、查准率**：分类成正样本中，实际的正样本的比例，（TP）/（TP+FP）
+ **真正例率（TPR）**：（TP）/（TP+FN），相当于Recall
+ **假正例率（FAR、FPR）**：（FP）/（FP+TN），也称误报率
+ **拒真率（FRR）**：实际的正样本中，分类成负样本的比例，（FN）/（TP+FN），相当于1-Recall
+ **F1分数**：精确率和召回率的调和指标，认为两个指标同等重要；
	+ 2×（precision×recall）/（precision+recall）
+ **F\_β分数**：（1+β×β）×（precision×recall）/（（β×β×precision）+recall）
+ **F2分数**：β等于2，召回率的重要程度是精确率的2倍
+ **G分数**：精确率和召回率的几何平均，sqrt(precision×recall)
----

+ **ROC曲线**
> 不平衡数据集中最常用的指标之一

![ROC曲线](https://s2.ax1x.com/2019/04/06/AWLVLF.jpg "ROC曲线")

+ **几个结论：**
	+ 阈值变大，样本分类成负样本的可能性增大（FP ↓，FN ↑）；阈值变小，样本分类成正样本的可能性增大（TP、FP ↑）；
	+ 好的分类模型应该尽可能位于坐标轴的左上方；随机猜测模型应该靠近于（0,0）和（1,1）这条对角线上；
	+ AUC面积值位于[0,1]，值越大说明模型分类越好；
+ **针对不平衡数据，应该如何选择阈值？**
	+ 相等错误率（ERR），FAR随阈值的增大而减少，FRR随阈值的增大而增大。当FAR=FRR时，此时阈值最合适。
----

